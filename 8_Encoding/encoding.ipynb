{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06514a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3def04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\sachi\\OneDrive\\Product Demand Forecasting\\DATA_FINAL\\Featured_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61567b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_ids = df['productid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8abf82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop('productid', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0692bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fc79996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df971c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Select the location column\n",
    "# location_col = df[['location']]  # Important: Use double brackets to keep it as DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "965ffae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder=OneHotEncoder(drop='first',sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f0b0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_encoded=encoder.fit_transform(location_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3243960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_encoded_df = pd.DataFrame(\n",
    "#     location_encoded,\n",
    "#     columns=encoder.get_feature_names_out(['location']),\n",
    "#     index=df.index  # keep same index for merging\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09d4de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Concatenate with original dataframe\n",
    "# df = pd.concat([df.drop('location', axis=1), location_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1077e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ebeddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 4: Get encoded column names\n",
    "# location_columns = location_encoded_df.columns.tolist()\n",
    "\n",
    "# # Step 5: Reorder columns — location columns first\n",
    "# df = df[location_columns + [col for col in df.columns if col not in location_columns]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa585d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>location</th>\n",
       "      <th>unitssold</th>\n",
       "      <th>promocodeused</th>\n",
       "      <th>price</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>adcampaign</th>\n",
       "      <th>isweekend</th>\n",
       "      <th>season</th>\n",
       "      <th>daytype</th>\n",
       "      <th>...</th>\n",
       "      <th>stocklevel</th>\n",
       "      <th>supplierdelay(days)</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>inventorytype</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>unit_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0080</td>\n",
       "      <td>L04</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>309.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>tv</td>\n",
       "      <td>no</td>\n",
       "      <td>spring</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>W2</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>-37.780</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2024</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0010</td>\n",
       "      <td>L01</td>\n",
<<<<<<< HEAD
       "      <td>3</td>\n",
=======
       "      <td>4</td>\n",
>>>>>>> fcf7e8f0 (Test the model just for verification and Correct the data)
       "      <td>Yes</td>\n",
       "      <td>300.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>winter</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>W3</td>\n",
       "      <td>Returned</td>\n",
       "      <td>-15.025</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>2024</td>\n",
<<<<<<< HEAD
       "      <td>Low</td>\n",
=======
       "      <td>Medium</td>\n",
>>>>>>> 2ce8498c (Removed Large File and Just test the model)
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0421</td>\n",
       "      <td>L07</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>300.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>autumn</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>W1</td>\n",
       "      <td>Returned</td>\n",
       "      <td>-15.025</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2024</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0412</td>\n",
       "      <td>L01</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>4</td>\n",
=======
       "      <td>2</td>\n",
>>>>>>> fcf7e8f0 (Test the model just for verification and Correct the data)
=======
       "      <td>4</td>\n",
>>>>>>> 2ce8498c (Removed Large File and Just test the model)
       "      <td>No</td>\n",
       "      <td>300.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>spring</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>3</td>\n",
       "      <td>W3</td>\n",
       "      <td>Repaired</td>\n",
       "      <td>-15.025</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2024</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0240</td>\n",
       "      <td>L07</td>\n",
<<<<<<< HEAD
<<<<<<< HEAD
       "      <td>5</td>\n",
=======
       "      <td>4</td>\n",
>>>>>>> fcf7e8f0 (Test the model just for verification and Correct the data)
=======
       "      <td>3</td>\n",
>>>>>>> 2ce8498c (Removed Large File and Just test the model)
       "      <td>Yes</td>\n",
       "      <td>300.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>spring</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>W3</td>\n",
       "      <td>Repaired</td>\n",
       "      <td>-15.025</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
<<<<<<< HEAD
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
<<<<<<< HEAD
       "<p>5 rows × 29 columns</p>\n",
=======
       "<p>5 rows × 28 columns</p>\n",
>>>>>>> fcf7e8f0 (Test the model just for verification and Correct the data)
=======
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
>>>>>>> 2ce8498c (Removed Large File and Just test the model)
       "</div>"
      ],
      "text/plain": [
       "  productid location  unitssold promocodeused   price  discount_percent  \\\n",
       "0     P0080      L04          7            No  309.98              20.0   \n",
<<<<<<< HEAD
       "1     P0010      L01          3           Yes  300.50               0.0   \n",
       "2     P0421      L07          3            No  300.50               0.0   \n",
       "3     P0412      L01          4            No  300.50               0.0   \n",
       "4     P0240      L07          5           Yes  300.50               0.0   \n",
       "\n",
       "  adcampaign isweekend  season  daytype  ...  stocklevel  supplierdelay(days)  \\\n",
       "0         tv        no  spring  Weekday  ...          61                    3   \n",
       "1    unknown       yes  winter  Weekend  ...          31                    2   \n",
       "2    unknown        no  autumn  Weekday  ...         116                    3   \n",
       "3    unknown        no  spring  Weekday  ...         168                    3   \n",
       "4    unknown        no  spring  Weekday  ...          68                    7   \n",
       "\n",
       "  warehouse inventorytype price_diff  month  dayofweek  week  year  unit_bin  \n",
       "0        W2         Fresh    -37.780      4          4    15  2024    Medium  \n",
       "1        W3      Returned    -15.025     12          5    50  2024       Low  \n",
       "2        W1      Returned    -15.025      9          4    39  2024       Low  \n",
       "3        W3      Repaired    -15.025      4          1    16  2024    Medium  \n",
       "4        W3      Repaired    -15.025      3          1    11  2024    Medium  \n",
       "\n",
       "[5 rows x 29 columns]"
=======
       "1     P0010      L01          4           Yes  300.50               0.0   \n",
       "2     P0421      L07          2            No  300.50               0.0   \n",
       "3     P0412      L01          4            No  300.50               0.0   \n",
       "4     P0240      L07          3           Yes  300.50               0.0   \n",
       "\n",
       "  adcampaign isweekend  season  daytype  ...  stocklevel  supplierdelay(days)  \\\n",
       "0         tv        no  spring  Weekday  ...          61                    3   \n",
       "1    unknown       yes  winter  Weekend  ...          31                    2   \n",
       "2    unknown        no  autumn  Weekday  ...         116                    3   \n",
       "3    unknown        no  spring  Weekday  ...         168                    3   \n",
       "4    unknown        no  spring  Weekday  ...          68                    7   \n",
       "\n",
       "  warehouse inventorytype price_diff  month  dayofweek  week  year  unit_bin  \n",
       "0        W2         Fresh    -37.780      4          4    15  2024    Medium  \n",
       "1        W3      Returned    -15.025     12          5    50  2024    Medium  \n",
       "2        W1      Returned    -15.025      9          4    39  2024       Low  \n",
       "3        W3      Repaired    -15.025      4          1    16  2024    Medium  \n",
       "4        W3      Repaired    -15.025      3          1    11  2024       Low  \n",
       "\n",
<<<<<<< HEAD
       "   week  year  \n",
       "0    15  2024  \n",
       "1    50  2024  \n",
       "2    39  2024  \n",
       "3    16  2024  \n",
       "4    11  2024  \n",
       "\n",
       "[5 rows x 28 columns]"
>>>>>>> fcf7e8f0 (Test the model just for verification and Correct the data)
=======
       "[5 rows x 29 columns]"
>>>>>>> 2ce8498c (Removed Large File and Just test the model)
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d4e4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "398e0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['promocodeused','isweekend']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8601f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize string values first\n",
    "# df['isweekend'] = df['isweekend'].astype(str).str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b12fd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['isweekend'] = df['isweekend'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ca5049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['isweekend'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96394eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['promocodeused']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f40da2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['promocodeused'] = df['promocodeused'].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "abd4136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['promocodeused'] = df['promocodeused'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d806919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Nulls in promocodeused:\", df['promocodeused'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d4d8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['promocodeused','isweekend']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28ae0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e9a2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['adcampaign'] = df['adcampaign'].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0acb6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['adcampaign'] = df['adcampaign'].replace(['unknown', 'unk', 'none', 'nan', ''], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "85d96aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['adcampaign'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4912670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['adcampaign'][df['adcampaign'].isnull()] = df['adcampaign'].dropna().sample(df['adcampaign'].isnull().sum(),replace=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c31bfd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['adcampaign'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf157b97",
   "metadata": {},
   "source": [
    "# Applying OneHotEncoding in AdCamapign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46a2e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Extract the column\n",
    "# ad_col = df[['adcampaign']]  # double brackets for DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bea64729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Initialize encoder\n",
    "# encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' to avoid dummy trap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "79806e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Fit and transform\n",
    "# ad_encoded = encoder.fit_transform(ad_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6dec1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 4: Create DataFrame from encoded array\n",
    "# ad_encoded_df = pd.DataFrame(\n",
    "#     ad_encoded,\n",
    "#     columns=encoder.get_feature_names_out(['adcampaign']),\n",
    "#     index=df.index  # keep index same to merge back\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46116821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Concatenate with original df (drop old 'adcampaign' column)\n",
    "# df = pd.concat([df.drop('adcampaign', axis=1), ad_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdfcda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "751e947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40429095",
   "metadata": {},
   "source": [
    "# Applying OneHotEncoding in these columns because its nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6acd305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal_cols = ['category', 'brand', 'material', 'warehouse', 'inventorytype']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fade09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_transformer = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('ohe', OneHotEncoder(drop='first', sparse_output=False), nominal_cols)\n",
    "#     ],\n",
    "#     remainder='passthrough'  # keep other columns unchanged\n",
    "# )\n",
    "\n",
    "# # Fit and transform\n",
    "# df_encoded = column_transformer.fit_transform(df)\n",
    "\n",
    "# # Get new feature names\n",
    "# ohe_feature_names = column_transformer.named_transformers_['ohe'].get_feature_names_out(nominal_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a66892c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "def84be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# df = pd.DataFrame(df_encoded, columns=np.append(ohe_feature_names, [col for col in df.columns if col not in nominal_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2456ba1",
   "metadata": {},
   "source": [
    "# Applying Binary Map Encoding in Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1bab20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['season'] = df['season'].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f623fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# season_order = {'spring': 0, 'summer': 1, 'autumn': 2, 'winter': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e594f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['season'] = df['season'].map(season_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79bfb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['season'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b88b6",
   "metadata": {},
   "source": [
    "# Applying Binary Map Encoding in DayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e96c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['daytype'] = df['daytype'].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a4f4f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['daytype'] = df['daytype'].map({'weekday': 0, 'weekend': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1e99f86",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "# df['daytype'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "637c1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5a69221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# # ✅ Clean binary columns\n",
    "# df['isweekend'] = df['isweekend'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "# df['promocodeused'] = df['promocodeused'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "\n",
    "# # ✅ Clean adcampaign\n",
    "# df['adcampaign'] = df['adcampaign'].astype(str).str.lower().str.strip()\n",
    "# df['adcampaign'] = df['adcampaign'].replace(['unknown', 'unk', 'none', 'nan', ''], pd.NA)\n",
    "\n",
    "# # ✅ Randomly fill missing adcampaign\n",
    "# n_missing = df['adcampaign'].isnull().sum()\n",
    "# if n_missing > 0:\n",
    "#     random_fill = df['adcampaign'].dropna().sample(n_missing, replace=True, random_state=42)\n",
    "#     random_fill.index = df[df['adcampaign'].isnull()].index\n",
    "#     df.loc[df['adcampaign'].isnull(), 'adcampaign'] = random_fill\n",
    "\n",
    "# # ✅ Drop unnecessary columns\n",
    "# df = df.drop(columns=['productid'])  # Keep 'unitssold' for later use\n",
    "\n",
    "# # 🔍 Define column types\n",
    "# categorical_features = [\n",
    "#     'location', 'adcampaign', 'brand',\n",
    "#     'category', 'material', 'warehouse',\n",
    "#     'inventorytype', 'season', 'daytype'\n",
    "# ]\n",
    "\n",
    "# binary_features = ['isweekend', 'promocodeused']\n",
    "\n",
    "# # ✅ Dynamically detect numerical columns (excluding object and categoricals)\n",
    "# numerical_features = [\n",
    "#     col for col in df.columns\n",
    "#     if col not in categorical_features + binary_features + ['unitssold']\n",
    "#     and df[col].dtype != 'object'\n",
    "# ]\n",
    "\n",
    "# # 🎯 Keep original target\n",
    "# target_col = 'unitssold'\n",
    "\n",
    "# # 🧾 Split features and target\n",
    "# X = df.drop(columns=[target_col])\n",
    "# y = df[target_col]\n",
    "\n",
    "# # 🏗️ Preprocessing Pipeline\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy='mean')),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ]), numerical_features),\n",
    "\n",
    "#     ('cat', Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#         ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "#     ]), categorical_features),\n",
    "\n",
    "#     ('bin', 'passthrough', binary_features)\n",
    "# ])\n",
    "\n",
    "# # ✅ Transform data\n",
    "# X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# # ✅ Final column names\n",
    "# feature_names = (\n",
    "#     numerical_features +\n",
    "#     list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)) +\n",
    "#     binary_features\n",
    "# )\n",
    "\n",
    "# X_final = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "# # ✅ Confirm\n",
    "# print(\"✅ Preprocessing Done Successfully\")\n",
    "# print(\"📊 Final Shape of X:\", X_final.shape)\n",
    "# print(\"🎯 Target (y) Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd9cdf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing Complete\n",
      "📊 Feature Shape: (511809, 48)\n",
      "🎯 Target Shape: (511809,)\n",
      "🏷️ Target Classes: ['High' 'Low' 'Medium']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 🧹 Clean binary columns\n",
    "df['isweekend'] = df['isweekend'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "df['promocodeused'] = df['promocodeused'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 📺 Clean adcampaign\n",
    "df['adcampaign'] = df['adcampaign'].astype(str).str.lower().str.strip()\n",
    "df['adcampaign'] = df['adcampaign'].replace(['unknown', 'unk', 'none', 'nan', ''], pd.NA)\n",
    "\n",
    "# 🎲 Random fill missing adcampaign\n",
    "n_missing = df['adcampaign'].isnull().sum()\n",
    "if n_missing > 0:\n",
    "    random_fill = df['adcampaign'].dropna().sample(n_missing, replace=True, random_state=42)\n",
    "    random_fill.index = df[df['adcampaign'].isnull()].index\n",
    "    df.loc[df['adcampaign'].isnull(), 'adcampaign'] = random_fill\n",
    "\n",
    "# 🚮 Drop unwanted column\n",
    "df = df.drop(columns=['productid'])\n",
    "\n",
    "# 🎯 Step 1: Bin unitssold\n",
    "def bin_unitssold(x):\n",
    "    if x in [1, 2, 3]:\n",
    "        return 'Low'\n",
    "    elif x in [4, 5, 6, 7]:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['unit_bin'] = df['unitssold'].apply(bin_unitssold)\n",
    "\n",
    "# 🎯 Step 2: Encode unit_bin\n",
    "le = LabelEncoder()\n",
    "df['unit_bin'] = le.fit_transform(df['unit_bin'])\n",
    "\n",
    "# 🚮 Step 3: Drop original unitssold\n",
    "df = df.drop(columns=['unitssold'])\n",
    "\n",
    "# 🏷️ Define column types\n",
    "categorical_features = [\n",
    "    'location', 'adcampaign', 'brand',\n",
    "    'category', 'material', 'warehouse',\n",
    "    'inventorytype', 'season', 'daytype'\n",
    "]\n",
    "\n",
    "binary_features = ['isweekend', 'promocodeused']\n",
    "\n",
    "numerical_features = [\n",
    "    col for col in df.columns\n",
    "    if col not in categorical_features + binary_features + ['unit_bin']\n",
    "    and df[col].dtype != 'object'\n",
    "]\n",
    "\n",
    "# 🧾 Split features and label (X, y)\n",
    "X = df.drop(columns=['unit_bin'])\n",
    "y = df['unit_bin']\n",
    "\n",
    "# 🏗️ Pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numerical_features),\n",
    "\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ]), categorical_features),\n",
    "\n",
    "    ('bin', 'passthrough', binary_features)\n",
    "])\n",
    "\n",
    "# ⚙️ Transform\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# 📋 Final column names\n",
    "feature_names = (\n",
    "    numerical_features +\n",
    "    list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)) +\n",
    "    binary_features\n",
    ")\n",
    "\n",
    "X_final = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "# ✅ Final confirmations\n",
    "print(\"✅ Preprocessing Complete\")\n",
    "print(\"📊 Feature Shape:\", X_final.shape)\n",
    "print(\"🎯 Target Shape:\", y.shape)\n",
    "print(\"🏷️ Target Classes:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85578a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>promocodeused</th>\n",
       "      <th>price</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>adcampaign</th>\n",
       "      <th>isweekend</th>\n",
       "      <th>season</th>\n",
       "      <th>daytype</th>\n",
       "      <th>temp(c)</th>\n",
       "      <th>rainfall(mm)</th>\n",
       "      <th>...</th>\n",
       "      <th>stocklevel</th>\n",
       "      <th>supplierdelay(days)</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>inventorytype</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>unit_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391975</th>\n",
       "      <td>L04</td>\n",
       "      <td>1</td>\n",
       "      <td>300.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>online</td>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>W2</td>\n",
       "      <td>Repaired</td>\n",
       "      <td>-15.025</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14230</th>\n",
       "      <td>L04</td>\n",
       "      <td>0</td>\n",
       "      <td>300.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tv</td>\n",
       "      <td>0</td>\n",
       "      <td>summer</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>W2</td>\n",
       "      <td>Repaired</td>\n",
       "      <td>-15.025</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  promocodeused  price  discount_percent adcampaign  isweekend  \\\n",
       "391975      L04              1  300.5               0.0     online          0   \n",
       "14230       L04              0  300.5               0.0         tv          0   \n",
       "\n",
       "        season  daytype  temp(c)  rainfall(mm)  ... stocklevel  \\\n",
       "391975  spring  Weekday     27.3           1.5  ...         14   \n",
       "14230   summer  Weekday     37.0          32.3  ...        151   \n",
       "\n",
       "       supplierdelay(days) warehouse  inventorytype  price_diff  month  \\\n",
       "391975                   5        W2       Repaired     -15.025      3   \n",
       "14230                    5        W2       Repaired     -15.025      8   \n",
       "\n",
       "        dayofweek  week  year unit_bin  \n",
       "391975          2    13  2024        2  \n",
       "14230           0    32  2024        2  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6026cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means after scaling:\n",
      " price                  0.0\n",
      "discount_percent       0.0\n",
      "temp(c)               -0.0\n",
      "rainfall(mm)          -0.0\n",
      "weight(kg)             0.0\n",
      "warranty(years)        0.0\n",
      "productrating         -0.0\n",
      "launchyear             0.0\n",
      "stocklevel            -0.0\n",
      "supplierdelay(days)   -0.0\n",
      "price_diff             0.0\n",
      "month                 -0.0\n",
      "dayofweek              0.0\n",
      "week                   0.0\n",
      "year                   0.0\n",
      "dtype: float64\n",
      "\n",
      "Standard deviations after scaling:\n",
      " price                  1.0\n",
      "discount_percent       1.0\n",
      "temp(c)                1.0\n",
      "rainfall(mm)           1.0\n",
      "weight(kg)             1.0\n",
      "warranty(years)        1.0\n",
      "productrating          1.0\n",
      "launchyear             1.0\n",
      "stocklevel             1.0\n",
      "supplierdelay(days)    1.0\n",
      "price_diff             1.0\n",
      "month                  1.0\n",
      "dayofweek              1.0\n",
      "week                   1.0\n",
      "year                   0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check mean and std of numerical columns after scaling\n",
    "means = X_final[numerical_features].mean()\n",
    "stds = X_final[numerical_features].std()\n",
    "\n",
    "print(\"Means after scaling:\\n\", np.round(means, 2))\n",
    "print(\"\\nStandard deviations after scaling:\\n\", np.round(stds, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f44e286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.to_csv(r\"C:\\Users\\sachi\\OneDrive\\Product Demand Forecasting\\DATA_FINAL\\encoded_data_X.csv\",index=False)\n",
    "y.to_csv(r\"C:\\Users\\sachi\\OneDrive\\Product Demand Forecasting\\DATA_FINAL\\encoded_data_Y.csv\",index=False)"
=======
   "outputs": [],
   "source": [
    "# df['daytype'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "637c1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5a69221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# # ✅ Clean binary columns\n",
    "# df['isweekend'] = df['isweekend'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "# df['promocodeused'] = df['promocodeused'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "\n",
    "# # ✅ Clean adcampaign\n",
    "# df['adcampaign'] = df['adcampaign'].astype(str).str.lower().str.strip()\n",
    "# df['adcampaign'] = df['adcampaign'].replace(['unknown', 'unk', 'none', 'nan', ''], pd.NA)\n",
    "\n",
    "# # ✅ Randomly fill missing adcampaign\n",
    "# n_missing = df['adcampaign'].isnull().sum()\n",
    "# if n_missing > 0:\n",
    "#     random_fill = df['adcampaign'].dropna().sample(n_missing, replace=True, random_state=42)\n",
    "#     random_fill.index = df[df['adcampaign'].isnull()].index\n",
    "#     df.loc[df['adcampaign'].isnull(), 'adcampaign'] = random_fill\n",
    "\n",
    "# # ✅ Drop unnecessary columns\n",
    "# df = df.drop(columns=['productid'])  # Keep 'unitssold' for later use\n",
    "\n",
    "# # 🔍 Define column types\n",
    "# categorical_features = [\n",
    "#     'location', 'adcampaign', 'brand',\n",
    "#     'category', 'material', 'warehouse',\n",
    "#     'inventorytype', 'season', 'daytype'\n",
    "# ]\n",
    "\n",
    "# binary_features = ['isweekend', 'promocodeused']\n",
    "\n",
    "# # ✅ Dynamically detect numerical columns (excluding object and categoricals)\n",
    "# numerical_features = [\n",
    "#     col for col in df.columns\n",
    "#     if col not in categorical_features + binary_features + ['unitssold']\n",
    "#     and df[col].dtype != 'object'\n",
    "# ]\n",
    "\n",
    "# # 🎯 Keep original target\n",
    "# target_col = 'unitssold'\n",
    "\n",
    "# # 🧾 Split features and target\n",
    "# X = df.drop(columns=[target_col])\n",
    "# y = df[target_col]\n",
    "\n",
    "# # 🏗️ Preprocessing Pipeline\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('num', Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy='mean')),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ]), numerical_features),\n",
    "\n",
    "#     ('cat', Pipeline([\n",
    "#         ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#         ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "#     ]), categorical_features),\n",
    "\n",
    "#     ('bin', 'passthrough', binary_features)\n",
    "# ])\n",
    "\n",
    "# # ✅ Transform data\n",
    "# X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# # ✅ Final column names\n",
    "# feature_names = (\n",
    "#     numerical_features +\n",
    "#     list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)) +\n",
    "#     binary_features\n",
    "# )\n",
    "\n",
    "# X_final = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "# # ✅ Confirm\n",
    "# print(\"✅ Preprocessing Done Successfully\")\n",
    "# print(\"📊 Final Shape of X:\", X_final.shape)\n",
    "# print(\"🎯 Target (y) Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd9cdf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing Complete\n",
      "📊 Feature Shape: (511809, 48)\n",
      "🎯 Target Shape: (511809,)\n",
      "🏷️ Target Classes: ['High' 'Low' 'Medium']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 🧹 Clean binary columns\n",
    "df['isweekend'] = df['isweekend'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "df['promocodeused'] = df['promocodeused'].astype(str).str.lower().str.strip().map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 📺 Clean adcampaign\n",
    "df['adcampaign'] = df['adcampaign'].astype(str).str.lower().str.strip()\n",
    "df['adcampaign'] = df['adcampaign'].replace(['unknown', 'unk', 'none', 'nan', ''], pd.NA)\n",
    "\n",
    "# 🎲 Random fill missing adcampaign\n",
    "n_missing = df['adcampaign'].isnull().sum()\n",
    "if n_missing > 0:\n",
    "    random_fill = df['adcampaign'].dropna().sample(n_missing, replace=True, random_state=42)\n",
    "    random_fill.index = df[df['adcampaign'].isnull()].index\n",
    "    df.loc[df['adcampaign'].isnull(), 'adcampaign'] = random_fill\n",
    "\n",
    "# 🚮 Drop unwanted column\n",
    "df = df.drop(columns=['productid'])\n",
    "\n",
    "# 🎯 Step 1: Bin unitssold\n",
    "def bin_unitssold(x):\n",
    "    if x in [1, 2, 3]:\n",
    "        return 'Low'\n",
    "    elif x in [4, 5, 6, 7]:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['unit_bin'] = df['unitssold'].apply(bin_unitssold)\n",
    "\n",
    "# 🎯 Step 2: Encode unit_bin\n",
    "le = LabelEncoder()\n",
    "df['unit_bin'] = le.fit_transform(df['unit_bin'])\n",
    "\n",
    "# 🚮 Step 3: Drop original unitssold\n",
    "df = df.drop(columns=['unitssold'])\n",
    "\n",
    "# 🏷️ Define column types\n",
    "categorical_features = [\n",
    "    'location', 'adcampaign', 'brand',\n",
    "    'category', 'material', 'warehouse',\n",
    "    'inventorytype', 'season', 'daytype'\n",
    "]\n",
    "\n",
    "binary_features = ['isweekend', 'promocodeused']\n",
    "\n",
    "numerical_features = [\n",
    "    col for col in df.columns\n",
    "    if col not in categorical_features + binary_features + ['unit_bin']\n",
    "    and df[col].dtype != 'object'\n",
    "]\n",
    "\n",
    "# 🧾 Split features and label (X, y)\n",
    "X = df.drop(columns=['unit_bin'])\n",
    "y = df['unit_bin']\n",
    "\n",
    "# 🏗️ Pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numerical_features),\n",
    "\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ]), categorical_features),\n",
    "\n",
    "    ('bin', 'passthrough', binary_features)\n",
    "])\n",
    "\n",
    "# ⚙️ Transform\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# 📋 Final column names\n",
    "feature_names = (\n",
    "    numerical_features +\n",
    "    list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)) +\n",
    "    binary_features\n",
    ")\n",
    "\n",
    "X_final = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "# ✅ Final confirmations\n",
    "print(\"✅ Preprocessing Complete\")\n",
    "print(\"📊 Feature Shape:\", X_final.shape)\n",
    "print(\"🎯 Target Shape:\", y.shape)\n",
    "print(\"🏷️ Target Classes:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6026cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means after scaling:\n",
      " price                  0.0\n",
      "discount_percent       0.0\n",
      "temp(c)               -0.0\n",
      "rainfall(mm)          -0.0\n",
      "weight(kg)             0.0\n",
      "warranty(years)        0.0\n",
      "productrating         -0.0\n",
      "launchyear             0.0\n",
      "stocklevel            -0.0\n",
      "supplierdelay(days)   -0.0\n",
      "price_diff             0.0\n",
      "month                 -0.0\n",
      "dayofweek              0.0\n",
      "week                   0.0\n",
      "year                   0.0\n",
      "dtype: float64\n",
      "\n",
      "Standard deviations after scaling:\n",
      " price                  1.0\n",
      "discount_percent       1.0\n",
      "temp(c)                1.0\n",
      "rainfall(mm)           1.0\n",
      "weight(kg)             1.0\n",
      "warranty(years)        1.0\n",
      "productrating          1.0\n",
      "launchyear             1.0\n",
      "stocklevel             1.0\n",
      "supplierdelay(days)    1.0\n",
      "price_diff             1.0\n",
      "month                  1.0\n",
      "dayofweek              1.0\n",
      "week                   1.0\n",
      "year                   0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check mean and std of numerical columns after scaling\n",
    "means = X_final[numerical_features].mean()\n",
    "stds = X_final[numerical_features].std()\n",
    "\n",
    "print(\"Means after scaling:\\n\", np.round(means, 2))\n",
    "print(\"\\nStandard deviations after scaling:\\n\", np.round(stds, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e286c",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "X_final.to_csv(\"Encoded_data_X.csv\",index=False)\n",
    "y.to_csv(\"Encoded_data_Y.csv\",index=False)"
>>>>>>> fcf7e8f0 (Test the model just for verification and Correct the data)
=======
    "X_final.to_csv(r\"C:\\Users\\sachi\\OneDrive\\Product Demand Forecasting\\DATA_FINAL\\encoded_data_X.csv\",index=False)\n",
    "y.to_csv(r\"C:\\Users\\sachi\\OneDrive\\Product Demand Forecasting\\DATA_FINAL\\encoded_data_Y.csv\",index=False)"
>>>>>>> 3afb1bf6 (Removed large files and updated .gitignore)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
